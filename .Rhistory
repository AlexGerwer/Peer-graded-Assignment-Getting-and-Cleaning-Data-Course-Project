ngapData <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE)
library(xlsx)
if(Sys.getenv("JAVA_HOME")!=""){
Sys.setenv(JAVA_HOME="")
}
library(rJava)
options(java.home="C:\Program Files (x86)\Java\jre1.8.0_251") library("xlsx")
fileURL <- “https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx”
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx.'
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx'
download.file(fileURL, destfile = "./NGAP.xlsx")
list.files("./")
install.packages("xlsx")
library(xlsx)
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, rowIndex = 18:23, colIndex = 7:15)
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, startRow=18, endRow=23, colIndex=7:15)
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, rowIndex = c(18:23), colIndex = c(7:15))
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, startRow=18, endRow=23)
dat <- read.xlsx("./NGAP.xlsx", header=TRUE, rowIndex = c(18:23), colIndex = c(7:15))
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, startRow=18, endRow=23)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx'
list.files("./")
install.packages("xlsx")
library(xlsx)
dat <- read.xlsx("./NGAP.xlsx", header=TRUE, rowIndex = c(18:23), colIndex = c(7:15))
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, rowIndex = c(18:23), colIndex = c(7:15))
sum(dat$Zip*dat$Ext,na.rm=T)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx'
download.file(fileURL, destfile = "./NGAP.xlsx", method="curl")
list.files("./")
install.packages("xlsx")
library(xlsx)
dat <- read.xlsx("./NGAP.xlsx", sheetIndex=1, header=TRUE, rowIndex = c(18:23), colIndex = c(7:15))
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("xml")
library(XML)
install.packages("XML")
librbary(XML)
library(XML)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
doc <- xmlTreeParse(fileURL, useInternalNodes=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc <- xmlTreeParse(fileUrl, useInternalNodes=TRUE)
doc <- xmlTreeParse(sub("s", "", fileUrl), useInternal = TRUE)
restaraunts <- xpathSApply(doc, "//li[@class='zipcode'], xmlValue")
restaraunts <- xpathSApply(doc, "//li[@class='zipcode']", xmlValue)
restaraunts
list(restaraunts)
list()
doc <- xmlTreeParse(sub("s", "", fileUrl), useInternalNodes = TRUE)
restaraunts <- xpathSApply(doc, "//li[@class='zipcode']", xmlValue)
restaraunts
list()
list(restaraunts)
code <- xpathSApply(rootNode, "//zipcode", xmlValue)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
code <- xpathSApply(rootNode, "//zipcode", xmlValue)
code
count(code==21231)
count <- length(code(b == 21231))
code
count <- length(which(code == 21231))
count
install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(sub("s", "", fileUrl), useInternal = TRUE)
rootNode <- xmlRoot(doc)
code <- xpathSApply(rootNode, "//zipcode", xmlValue)
count <- length(which(code == 21231))
count
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "./initialData.csv")
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "./initialData.csv")
install.packages("data.table")
library(data.table)
DT <- fread(fileURL)
DT <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
DT
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time("mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)")
system.time("sample <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)")
system.time("s <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)")
s
start.time <- Sys.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
ptm <- proc.time()
tapply(DT$pwgtp15,DT$SEX,mean)
proc.time() - ptm
ptm <- proc.time()
sapply(split(DT$pwgtp15,DT$SEX),mean)
proc.time() - ptm
ptm <- proc.time()
DT[,mean(pwgtp15),by=SEX]
proc.time() - ptm
ptm <- proc.time()
mean(DT$pwgtp15,by=DT$SEX)
proc.time() - ptm
ptm <- proc.time()
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
proc.time() - ptm
options(digits.secs = 6)
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
options(digits.secs = 8)
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
options(digits.secs = 8)
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
x <- proc.time() - ptm
y = formatC(x, digits = 8, format = "f")
y
ptm <- proc.time()
p = formatC(ptm, digits = 8, format = "f")
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
x <- proc.time() - p
y = formatC(x, digits = 8, format = "f")
y
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
mean_cal <- function(DT) {
mean_val <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
return(mean_val)
}
start.time <- Sys.time()
mean_cal(DT)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
end.time
proc.time()
system.time(mean_cal(DT))
mbm = microbenchmark(
a1 = mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15),
a2 = tapply(DT$pwgtp15,DT$SEX,mean),
a3 = sapply(split(DT$pwgtp15,DT$SEX),mean),
a4= DT[,mean(pwgtp15),by=SEX],
a5= mean(DT$pwgtp15,by=DT$SEX),
a6= rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2],
times = 100
)
a1 = mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) ,
a2 = tapply(DT$pwgtp15,DT$SEX,mean) ,
a3 = sapply(split(DT$pwgtp15,DT$SEX),mean) ,
a4= DT[,mean(pwgtp15),by=SEX] ,
a5= mean(DT$pwgtp15,by=DT$SEX) ,
a6= rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2] ,
times = 100
)
mbm
mean_cal_1 <- function(DT) {
mean_val <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
return(mean_val)
}
mean_cal_2 <- function(DT) {
mean_val <- tapply(DT$pwgtp15,DT$SEX,mean)
return(mean_val)
}
mean_cal_3 <- function(DT) {
mean_val <- sapply(split(DT$pwgtp15,DT$SEX),mean)
return(mean_val)
}
mean_cal_4 <- function(DT) {
mean_val <- DT[,mean(pwgtp15),by=SEX]
return(mean_val)
}
mean_cal_5 <- function(DT) {
mean_val <- mean(DT$pwgtp15,by=DT$SEX)
return(mean_val)
}
mean_cal_6 <- function(DT) {
mean_val <- rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
return(mean_val)
}
mbm = microbenchmark(
a1 = mean_cal_1(DT),
a2 = mean_cal_2(DT),
a3 = mean_cal_3(DT),
a4 = mean_cal_4(DT),
a5 = mean_cal_5(DT),
a6 = mean_cal_6(DT),
times = 100
)
mbm
install.packages("microbenchmark")
library(microbenchmark)
mean_cal_1 <- function(DT) {
mean_val <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
return(mean_val)
}
mean_cal_2 <- function(DT) {
mean_val <- tapply(DT$pwgtp15,DT$SEX,mean)
return(mean_val)
}
mean_cal_3 <- function(DT) {
mean_val <- sapply(split(DT$pwgtp15,DT$SEX),mean)
return(mean_val)
}
mean_cal_4 <- function(DT) {
mean_val <- DT[,mean(pwgtp15),by=SEX]
return(mean_val)
}
mean_cal_5 <- function(DT) {
mean_val <- mean(DT$pwgtp15,by=DT$SEX)
return(mean_val)
}
mean_cal_6 <- function(DT) {
mean_val <- rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
return(mean_val)
}
mbm = microbenchmark(
a1 = mean_cal_1(DT),
a2 = mean_cal_2(DT),
a3 = mean_cal_3(DT),
a4 = mean_cal_4(DT),
a5 = mean_cal_5(DT),
a6 = mean_cal_6(DT),
times = 100
)
mbm
install.packages("microbenchmark")
library(microbenchmark)
mean_cal_1 <- function(DT) {
mean_val <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
return(mean_val)
}
mean_cal_2 <- function(DT) {
mean_val <- tapply(DT$pwgtp15,DT$SEX,mean)
return(mean_val)
}
mean_cal_3 <- function(DT) {
mean_val <- sapply(split(DT$pwgtp15,DT$SEX),mean)
return(mean_val)
}
mean_cal_4 <- function(DT) {
mean_val <- DT[,mean(pwgtp15),by=SEX]
return(mean_val)
}
mean_cal_5 <- function(DT) {
mean_val <- mean(DT$pwgtp15,by=DT$SEX)
return(mean_val)
}
#mean_cal_6 <- function(DT) {
#  mean_val <- rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
#  return(mean_val)
#}
mbm = microbenchmark(
a1 = mean_cal_1(DT),
a2 = mean_cal_2(DT),
a3 = mean_cal_3(DT),
a4 = mean_cal_4(DT),
a5 = mean_cal_5(DT),
#a6 = mean_cal_6(DT),
times = 100
)
mbm
install.packages("microbenchmark")
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
install.packages("data.table")
library(data.table)
DT <- fread(fileURL)
install.packages("microbenchmark")
library(microbenchmark)
mean_cal_1 <- function(DT) {
mean_val <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
return(mean_val)
}
mean_cal_2 <- function(DT) {
mean_val <- tapply(DT$pwgtp15,DT$SEX,mean)
return(mean_val)
}
mean_cal_3 <- function(DT) {
mean_val <- sapply(split(DT$pwgtp15,DT$SEX),mean)
return(mean_val)
}
mean_cal_4 <- function(DT) {
mean_val <- DT[,mean(pwgtp15),by=SEX]
return(mean_val)
}
mean_cal_5 <- function(DT) {
mean_val <- mean(DT$pwgtp15,by=DT$SEX)
return(mean_val)
}
mean_cal_6 <- function(DT) {
mean_val <- rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
return(mean_val)
}
mbm = microbenchmark(
a1 = mean_cal_1(DT),
a2 = mean_cal_2(DT),
a3 = mean_cal_3(DT),
a4 = mean_cal_4(DT),
a5 = mean_cal_5(DT),
#a6 = mean_cal_6(DT),
times = 100
)
mbm
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# Replace your key and secret below.
myapp <- oauth_app("github",
key = "Iv1.066a4509471af41c",
secret = "37e585ad69851e666374008ad0caf2dc35052129"
)
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
puts "Hello, World!"
puts RUBY_DESCRIPTION
#install.packages("jsonlite")
library(jsonlite)
#install.packages("httpuv")
library(httpuv)
#install.packages("httr")
library(httr)
# Can be github, linkedin etc depending on application
oauth_endpoints("github")
# Change based on your appname, key, and secret
myapp <- oauth_app(appname = "Week 2 Quiz Problem 1",
key = "Iv1.066a4509471af41c",
secret = "37e585ad69851e666374008ad0caf2dc35052129")
# Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
# Take action on http error
stop_for_status(req)
# Extract content from a request
json1 = content(req)
# Convert to a data.frame
gitDF = jsonlite::fromJSON(jsonlite::toJSON(json1))
# Subset data.frame
gitDF[gitDF$full_name == "jtleek/datasharing", "created_at"]
install.packages("RMySQL", type = "source")
library(RMySQL)
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="user",
password = "password", dbname="db")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="AlexGerwer",
password = "password", dbname="db")
con <- dbConnect(MySQL(), host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", user="AlexGerwer")
con <- dbConnect(MySQL(),user="AlexGerwer", host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
con <- dbConnect(MySQL(),user="AlexGerwer", host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="AlexGerwer",
password = "password", dbname="db")
#default_authentication_plugin=caching_sha2_password
default_authentication_plugin=mysql_native_password
con <- dbConnect(RMySQL(), host="127.0.0.1", port= 3306, user="AlexGerwer",
password = "password", dbname="db")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="AlexGerwer",
password = "password", dbname="db")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="user",
password = "password", dbname="db")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="root",
password = "password", dbname="db")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="root",
password = "password", dbname="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="root",
password = "password", dbname="acs")
acs.head()
acs
library (RCurl)
download <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
acs <- read.csv (text = download)
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="root",
password = "password", dbname="acs")
acs.head()
library(sqldf)
library(RMySQL)
library(sqldf)
install.packages('sqldf')
library('sqldf')
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
ALTER USER 'root'@'localhost'
IDENTIFIED WITH mysql_native_password BY 'password'
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';
sqldf("select pwgtp1 from acs where AGEP < 50")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table::data.table(read.csv(f))
query1 <- sqldf("select * from acs where AGEP \lt< 50 and pwgtp1")
query1 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
query2 <- sqldf("select * from acs")
query3 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query4 <- sqldf("select pwgtp1 from acs")
con = url('http://biostat.jhsph.edu/~jleek/contact.html')
htmlCode = readLines(con)
htmlCode
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
nchar(htmlCode[10])
nchar(htmlCode[20])
close(con)
suppressMessages(library(dplyr))
setwd("C:\Users\ASG\Desktop\Week 3 Quiz")
# Set the working directory
setwd("C:/Users/ASG/Desktop/Peer-graded Assignment Getting and Cleaning Data Course Project")
# Load the required packages
LoadRequiredPackages <- function() {
# Load the required packages.
if (!require('pacman')) {
install.packages('pacman')
}
pacman::p_load(data.table, dplyr, dtplyr, readr, tidyr)
}
# Load the data
dataset.dir <- 'UCI HAR Dataset'
if (!dir.exists(dataset.dir)) {
dataset.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
temp <- tempfile()
download.file(dataset.url, temp)
unzip(temp)
}
# Read the data and tidy up test and train sets
# Read data files for X
path.train  <-  file.path(dataset.dir, 'train')
x_train_data  <- read.table(file.path(path.train, 'X_train.txt'))
path.test  <-  file.path(dataset.dir, 'test')
x_test_data <- read.table(file.path(path.test, 'X_test.txt'))
# Read data files for y
y_train_data  <- read.table(file.path(path.train, 'y_train.txt') , col.names = "Activity", colClasses = "factor")
y_test_data <- read.table(file.path(path.test, 'y_test.txt') , col.names = "Activity", colClasses = "factor")
# Read subject files
subject_train  <-  read.table(file.path(path.train, 'subject_train.txt'), col.names = "Subject", colClasses = "factor")
subject_test  <-  read.table(file.path(path.test, 'subject_test.txt') , col.names = "Subject", colClasses = "factor")
# Load feature names
feature_names  <-  read.table(file.path(dataset.dir, 'features.txt'),
col.names = c("feature_number", "feature_label"),
stringsAsFactors = FALSE)
# Make sure the labels follow the order of the column number (not really needed,
# given the content of the actual features.txt, but it could be required if the
# file changes)
feature_names  <-  feature_names[order(feature_names$feature_number), ]
# 1. Merge the training and the test sets to create one data set.
# The call to rbind simply puts one dataset after the other, keeping the order
# This is possible because both tables have the same variables
full_dataset <- rbind(x_train_data, x_test_data)
# 2. Extract only the measurements on the mean and standard deviation for each measurement.
# Create a vector with the indexes of the variable names including "mean" or "std" in the name
subset_columns <- grep("mean|std", feature_names$feature_label)
# Extract those variables from full_dataset
selected_dataset <- full_dataset[, subset_columns]
# Add the activity labels and subject names in the first and second columns
selected_dataset <- cbind(rbind(y_train_data, y_test_data),
rbind(subject_train, subject_test), selected_dataset)
# 3. Use descriptive activity names to name the activities in the data set
# Load activity names from the file
activity_labels  <-  read.table(file.path(dataset.dir, 'activity_labels.txt'),
col.names = c("Activity_number", "Activity_label"),
colClasses = c("integer", "factor"))
# Make sure the labels follow the order of the number in the first column
activity_labels  <-  activity_labels[order(activity_labels$Activity_number), ]
# Assign the descriptive labels to the factors
levels(selected_dataset$Activity)  <-  activity_labels$Activity_label
# 4. Appropriately labels the data set with descriptive variable names.
# When feature_names$feature_label were assigned to names()
# the first 2 columns of selected_dataset were preserved, as they
# already were correct
# Replace ^t with Time
names(selected_dataset)[3:length(names(selected_dataset))] <-
gsub("^t", "Time", feature_names$feature_label[subset_columns])
# Replace ^f with Frequency
names(selected_dataset) <- gsub("^f", "Frequency", names(selected_dataset))
# Replace Acc with Acceleration
names(selected_dataset) <- gsub("Acc", "Acceleration", names(selected_dataset), fixed = TRUE)
# Replace Mag with Magnitude
names(selected_dataset) <- gsub("Mag", "Magnitude", names(selected_dataset), fixed = TRUE)
# Replace jerk with Jerk (for consistency)
names(selected_dataset) <- gsub("jerk", "Jerk", names(selected_dataset), fixed = TRUE)
# Eliminate ()
names(selected_dataset) <- gsub("()", "", names(selected_dataset), fixed = TRUE)
# 5. Create a 2nd, separate tidy data set with the average of each variable for each activity and subject.
# The suffix "variable_mean" is added to each variable name
library(magrittr)
tidy_dataset <- selected_dataset %>%
dplyr::group_by (Activity, Subject) %>%
dplyr::summarise_all(list(variable_mean = mean))
# Write the result to the file tidy_dataset.txt with column headers
write.table(tidy_dataset, file = "tidy_dataset.txt", col.names = TRUE, row.names = FALSE)
test_dataset <- read.table("tidy_dataset.txt", header = TRUE)
View(test_dataset)
